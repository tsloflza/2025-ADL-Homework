{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-16T12:44:05.320140Z",
     "iopub.status.busy": "2025-09-16T12:44:05.319378Z",
     "iopub.status.idle": "2025-09-16T12:44:08.931489Z",
     "shell.execute_reply": "2025-09-16T12:44:08.930728Z",
     "shell.execute_reply.started": "2025-09-16T12:44:05.320113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "%pip install datasets torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-16T12:44:08.933348Z",
     "iopub.status.busy": "2025-09-16T12:44:08.933043Z",
     "iopub.status.idle": "2025-09-16T12:44:08.940296Z",
     "shell.execute_reply": "2025-09-16T12:44:08.939550Z",
     "shell.execute_reply.started": "2025-09-16T12:44:08.933318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# Copyright The HuggingFace Team and The HuggingFace Inc. team. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"\n",
    "Fine-tuning a ü§ó Transformers model on multiple choice relying on the accelerate library without using a Trainer.\n",
    "\"\"\"\n",
    "# You can also adapt this script on your own multiple choice task. Pointers for this are left as comments.\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "from accelerate.utils import set_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForMultipleChoice,\n",
    "    AutoTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T12:44:08.941316Z",
     "iopub.status.busy": "2025-09-16T12:44:08.941074Z",
     "iopub.status.idle": "2025-09-16T12:44:08.961419Z",
     "shell.execute_reply": "2025-09-16T12:44:08.960847Z",
     "shell.execute_reply.started": "2025-09-16T12:44:08.941294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"===== ps_inference.py =====\")\n",
    "\n",
    "# ËÆÄÂèñÂëΩ‰ª§ÂàóÂèÉÊï∏\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--context_file\", type=str, required=True)\n",
    "parser.add_argument(\"--test_file\", type=str, required=True)\n",
    "args_dict = parser.parse_args().__dict__\n",
    "\n",
    "args = SimpleNamespace(\n",
    "    test_file=args_dict[\"test_file\"],\n",
    "    context_file=args_dict[\"context_file\"],\n",
    "    max_seq_length=512,\n",
    "    pad_to_max_length=False,\n",
    "    model_name_or_path=\"downloads/ps2_model\",\n",
    "    per_device_eval_batch_size=1,\n",
    "    output_path=\"ps_result.csv\",\n",
    "    seed=1234,\n",
    ")\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T12:44:08.963041Z",
     "iopub.status.busy": "2025-09-16T12:44:08.962850Z",
     "iopub.status.idle": "2025-09-16T12:44:08.980567Z",
     "shell.execute_reply": "2025-09-16T12:44:08.979870Z",
     "shell.execute_reply.started": "2025-09-16T12:44:08.963027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the seed now.\n",
    "if args.seed is not None:\n",
    "    set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T12:44:08.981557Z",
     "iopub.status.busy": "2025-09-16T12:44:08.981330Z",
     "iopub.status.idle": "2025-09-16T12:44:09.246322Z",
     "shell.execute_reply": "2025-09-16T12:44:09.245569Z",
     "shell.execute_reply.started": "2025-09-16T12:44:08.981536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get the datasets\n",
    "\n",
    "with open(args.context_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    contexts = json.load(f)\n",
    "\n",
    "# Inference dataset loader (without label)\n",
    "def load_paragraph_selection_test(file_path, contexts):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        examples = json.load(f)\n",
    "\n",
    "    data = {\n",
    "        \"id\": [],\n",
    "        \"question\": [],\n",
    "        \"paragraphs\": [],\n",
    "    }\n",
    "\n",
    "    for ex in examples:\n",
    "        qid = ex[\"id\"]\n",
    "        question = ex[\"question\"]\n",
    "        para_ids = ex[\"paragraphs\"]\n",
    "\n",
    "        para_texts = [contexts[pid] for pid in para_ids]\n",
    "\n",
    "        data[\"id\"].append(qid)\n",
    "        data[\"question\"].append(question)\n",
    "        data[\"paragraphs\"].append(para_texts)\n",
    "\n",
    "    return datasets.Dataset.from_dict(data)\n",
    "\n",
    "# load test split\n",
    "dataset_splits = {}\n",
    "if args.test_file is not None:\n",
    "    dataset_splits[\"test\"] = load_paragraph_selection_test(args.test_file, contexts)\n",
    "\n",
    "raw_datasets = datasets.DatasetDict(dataset_splits)\n",
    "\n",
    "print(raw_datasets)\n",
    "print(raw_datasets[\"test\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T12:44:09.247398Z",
     "iopub.status.busy": "2025-09-16T12:44:09.247154Z",
     "iopub.status.idle": "2025-09-16T12:44:09.371413Z",
     "shell.execute_reply": "2025-09-16T12:44:09.370732Z",
     "shell.execute_reply.started": "2025-09-16T12:44:09.247372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. ËºâÂÖ• config\n",
    "config = AutoConfig.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "# 2. ËºâÂÖ• tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "# 3. ËºâÂÖ• model (Âè™ÂÅöÊé®Ë´ñÔºå‰∏çÈúÄË¶Å from_tf)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# 4. Ë™øÊï¥ embedding Â§ßÂ∞èÔºàÈÅøÂÖç tokenizer Êñ∞Â¢ûÂ≠óÂÖ∏ÈÄ†Êàê index errorÔºâ\n",
    "embedding_size = model.get_input_embeddings().weight.shape[0]\n",
    "if len(tokenizer) > embedding_size:\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 5. padding ÊñπÂºè (inference ÈÄöÂ∏∏ÊúÉÁî® dynamic padding ÊØîËºÉÂø´)\n",
    "padding = \"max_length\" if args.pad_to_max_length else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T12:44:09.372821Z",
     "iopub.status.busy": "2025-09-16T12:44:09.372297Z",
     "iopub.status.idle": "2025-09-16T12:44:14.067442Z",
     "shell.execute_reply": "2025-09-16T12:44:14.066902Z",
     "shell.execute_reply.started": "2025-09-16T12:44:09.372795Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Preprocessing (for inference, no labels) ---\n",
    "def preprocess_function(examples):\n",
    "    questions = examples[\"question\"]             # list[str]\n",
    "    paragraphs_list = examples[\"paragraphs\"]     # list[list[str]]\n",
    "\n",
    "    first_sentences = []\n",
    "    second_sentences = []\n",
    "\n",
    "    for q, paras in zip(questions, paragraphs_list):\n",
    "        assert len(paras) == 4, f\"ÊØèÈ°åÊáâË©≤Ë¶ÅÊúâ 4 ÂÄãÈÅ∏È†ÖÔºå‰ΩÜÂæóÂà∞ {len(paras)}\"\n",
    "        first_sentences.extend([q] * 4)\n",
    "        second_sentences.extend(paras)\n",
    "\n",
    "    # Tokenize (flat)\n",
    "    tokenized_examples = tokenizer(\n",
    "        first_sentences,\n",
    "        second_sentences,\n",
    "        max_length=args.max_seq_length,\n",
    "        padding=\"max_length\" if args.pad_to_max_length else False,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    # reshape ‚Üí [batch_size, num_choices, seq_len]\n",
    "    result = {k: [v[i:i + 4] for i in range(0, len(v), 4)]\n",
    "              for k, v in tokenized_examples.items()}\n",
    "\n",
    "    # ‰øùÁïô id Ë∑ü paragraphsÔºåÊñπ‰æøÂæåÁ∫åËº∏Âá∫\n",
    "    result[\"id\"] = examples[\"id\"]\n",
    "    result[\"paragraphs\"] = examples[\"paragraphs\"]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# --- Dataset preprocessing ---\n",
    "processed_datasets = raw_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"test\"].column_names\n",
    ")\n",
    "test_dataset = processed_datasets[\"test\"]\n",
    "\n",
    "\n",
    "# --- Collator (for inference only) ---\n",
    "def inference_collator(features):\n",
    "    ids = [f.pop(\"id\") for f in features]\n",
    "    paras = [f.pop(\"paragraphs\") for f in features]\n",
    "\n",
    "    # Â±ïÂπ≥Êàê flat list\n",
    "    flat_features = []\n",
    "    for f in features:\n",
    "        for i in range(len(f[\"input_ids\"])):  # num_choices (4)\n",
    "            flat_features.append({k: f[k][i] for k in f.keys()})\n",
    "\n",
    "    # padding ‚Üí ÂÜç reshape Âõû [batch, num_choices, seq_len]\n",
    "    batch = tokenizer.pad(\n",
    "        flat_features,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    batch_size = len(features)\n",
    "    num_choices = len(features[0][\"input_ids\"])\n",
    "    for k in batch.keys():\n",
    "        batch[k] = batch[k].view(batch_size, num_choices, -1)\n",
    "\n",
    "    batch[\"id\"] = ids\n",
    "    batch[\"paragraphs\"] = paras\n",
    "    return batch\n",
    "\n",
    "\n",
    "# --- DataLoader ---\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    collate_fn=inference_collator,\n",
    "    batch_size=args.per_device_eval_batch_size\n",
    ")\n",
    "\n",
    "\n",
    "# --- Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-16T12:44:14.068395Z",
     "iopub.status.busy": "2025-09-16T12:44:14.068146Z",
     "iopub.status.idle": "2025-09-16T12:46:27.377239Z",
     "shell.execute_reply": "2025-09-16T12:46:27.376609Z",
     "shell.execute_reply.started": "2025-09-16T12:44:14.068378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Inference =====\n",
    "ps_predictions = []\n",
    "\n",
    "for step, batch in enumerate(tqdm(test_dataloader, desc=\"Running Inference\")):\n",
    "    inputs = {k: v.to(device) for k, v in batch.items() if k not in [\"id\", \"paragraphs\"]}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    pred_choices = outputs.logits.argmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    for i, choice in enumerate(pred_choices):\n",
    "        qid = batch[\"id\"][i]\n",
    "        pred_para = batch[\"paragraphs\"][i][choice]\n",
    "        ps_predictions.append({\n",
    "            \"id\": qid,\n",
    "            \"prediction\": pred_para\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T12:46:27.378312Z",
     "iopub.status.busy": "2025-09-16T12:46:27.377997Z",
     "iopub.status.idle": "2025-09-16T12:46:27.419149Z",
     "shell.execute_reply": "2025-09-16T12:46:27.418619Z",
     "shell.execute_reply.started": "2025-09-16T12:46:27.378292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===== Save Inference Results =====\n",
    "if args.output_path is not None:\n",
    "    with open(args.output_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"id\", \"prediction\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(ps_predictions)\n",
    "\n",
    "    print(f\"‚úÖ Saved predictions to {args.output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13653249,
     "sourceId": 114453,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 451533,
     "modelInstanceId": 434681,
     "sourceId": 582224,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
